**Solve RL With This One Weird Trick**  
==The previous state-of-the-art model for playing vintage Atari games took advantage of a number of advances in reinforcement learning (RL). The new champion is a basic RL architecture plus a trick borrowed from image generation.==  
**What’s new:** ==A team led by Florin Gogianu, Tudor Berariu, and colleagues== ==found== ==that spectral normalization, a technique that limits the degree of variation between representations of similar inputs, improved an RL model’s performance more than several recent innovations combined.== ==The team included researchers at Bitdefender, Deepmind, Imperial College London, Technical University of Cluj-Napoca, and University College London.==  
**Key insight:** ==In reinforcement learning, a model observes its environment (say, the Atari game== ==Pong====), chooses an action based on its observation (such as moving the paddle), and receives a reward for a desirable outcome (like scoring a point). Learning in this way can be difficult because, as a model selects different actions, its training data (observations and rewards) change. Mutable training data poses a similar problem for generative adversarial networks (GANs), where generator and discriminator networks influence each other even as they themselves change. Spectral normalization has been== ==shown== ==to help GANs learn by moderating these changes. It could also be beneficial in reinforcement learning.==  
**How it works:** ==The authors added spectral normalization to a== ==C51====, a convolutional neural network designed for reinforcement learning. The authors trained their model on tasks in the== ==Arcade Learning Environment====, a selection of games in which the actions are valid Atari controller movements.==

- ==Given an observation, a C51 predicts a set of distributions of the likely reward for taking each possible action. Then it selects the action that would bring the highest expected reward. During training, it refines its prediction by sampling and comparing predicted rewards to actual rewards.==
- ==Spectral normalization constrains parameter values in network layers, such that the distance between any two predictions is, at most, the distance between the inputs times a constant factor (chosen by the user). The smaller the factor, the more similar a network’s predictions must be. During training, spectral normalization limits the magnitude of a layer’s weights. If an update exceeds that limit, it divides the weights evenly so their magnitude is equal to the limit.==
- ==The authors argue that limiting weight changes is akin to dampening learning rates. They devised an optimization method that lowered the model’s learning rate proportionately to spectral normalization’s limit on the weights. Models trained either way performed nearly equally.==

**Results:** ==Using spectral normalization on every layer impeded performance, but using it on only the second-to-last layer led the model to achieve a higher median reward. The authors compared their C51 with spectral normalization on the second-to-last layer against== ==Rainbow====, the previous state of the art, which outfits a C51 with a variety of RL techniques. In 54 Atari games, the authors’ approach achieved a 248.45 median reward, outperforming Rainbow’s 227.05 median reward.==  
**Why it matters:** ==Applying techniques from one area of machine learning, such as GANs, to a superficially different area, such as RL, can be surprisingly fruitful! In this case, it opens the door to much simpler RL models and perhaps opportunities to improve existing techniques.==  
**We’re thinking:** ==People who have expertise in multiple disciplines can be exceptionally creative, spotting opportunities for cross-fertilization among disparate fields. AI is now big enough to offer a cornucopia of opportunities for such interdisciplinary insight.==
 \> From \<[https://mail.google.com/mail/u/0/#inbox/FMfcgzGkZstpSFhLXLgFWbJPpgJhFmpj](https://mail.google.com/mail/u/0/#inbox/FMfcgzGkZstpSFhLXLgFWbJPpgJhFmpj)\>  

![Siamese networks With variance, invariance and cov...](Exported%20image%2020260209130324-0.gif)

**More Reliable Pretraining**  
Pretraining methods generate basic representations for later fine-tuning, but they’re prone to certain issues that can throw them off-kilter. New work proposes a solution.  
**What’s new:** Researchers at Facebook, PSL Research University, and New York University led by Adrien Bardes devised an unsupervised pretraining method they call [Variance-Invariance-Covariance Regularization](https://info.deeplearning.ai/e3t/Btc/LX+113/cJhC404/VVHKnN1kyNsjW8FHScq6nY05mW8hW1h34wH5nzMXl4nJ3q3n5V1-WJV7CgZdtW694whJ6CJqftW2mrS761R2YDjW3c5CKC13yYwdW1XwmvV31RXVSN8fsTgGVphbfW3LbtpC5LvgxNW1bDthH2YmZnXVMhJ_d3bxQ98W2jv6l_2yWyjsW5SKhJy4Q74c7W3yNK3n1kwGZ9W1ZKZHX34wdSFW7vLGH17h5d01W3J6XBM6XDdDdW32RDY323gpdTW4XhwGw95RX4wW1xwZDB7Cp4DgW6xV3rG7M7bZwW4KhmwT13YzdbN3cDhQnNK0Z934cL1) (VICReg). VICReg helps a model learn useful representations based on well understood statistical principles.  
**Key insight:** Pretraining methods can suffer from three common failings: Generating an identical representation for different input examples (which leads to predicting the mean consistently in linear regression), generating dissimilar representations for examples that humans find similar (for instance, the same object viewed from two angles), and generating redundant parts of a representation (say, multiple vectors that represent two eyes in a photo of a face). Statistically speaking, these problems boil down to issues of variance, invariance, and covariance respectively.   
**How it works:** VICReg manages variance, invariance, and covariance via different terms in a loss function. The authors used it to pretrain a [ResNet-50](https://info.deeplearning.ai/e3t/Btc/LX+113/cJhC404/VVHKnN1kyNsjW8FHScq6nY05mW8hW1h34wH5nzMXl4nJ3q3n5V1-WJV7CgYV1VFX6BP2mCd0GW3gndnK5HH2yLVs8XjK18DKM-N2vxz42GcV7mW3-LY793GTQt-W46YZZy8cQLR0W82lHzp3RZL6wN24jJPyzMHJLW7d6ryT8mzJrzW3x23gY96S0LjW3bhy4-3PVF1SW1MryB-6G5JD6W3GB5NK57sy70W8kdfRk762YvWW1p_6b258k078W18f7XT53CqQ3VBfDMC8dMkw0W3-KNQk7rW9kNW7m0nhj9hX0KjW3wprV61c8vC_316v1) on [ImageNet](https://info.deeplearning.ai/e3t/Btc/LX+113/cJhC404/VVHKnN1kyNsjW8FHScq6nY05mW8hW1h34wH5nzMXl4np3q3mQV1-WJV7CgN4VW4v-yHh6Nkyq2W2bmBsY2DHdhGW4JcNSl43N65QW5x2gL645kmhjVvc1ck62MwKFW4DS-Zz7gXz5vW3_s2zm15x7ddW95CkxF2BVHFdN4z445HCzPfsVwCxCT5NJG5yW8yPzX68mr3sZVJ7wxc5VH60QW5CYy8_2CVq0GW2HRzD56Z57FKW1W7HGz8W2_SsW6KnBnY8-ZhlYVjQDpL88HYR8W2lfsns6h_Xc339-V1) without labels.

- To discourage similar representations of every example, the variance term of VICReg’s loss function computes the variance within an input batch’s representations; that is, the average amount by which each value differs from the mean. This term penalizes the model if this variance falls below a threshold.
- The covariance term computes correlations between elements of each representation. It sums the correlations and penalizes the model for extracting correlated features within a given representation.
- To prevent dissimilar representations of similar examples, VICReg borrows an idea from [contrastive learning](https://info.deeplearning.ai/e3t/Btc/LX+113/cJhC404/VVHKnN1kyNsjW8FHScq6nY05mW8hW1h34wH5nzMXl4nJ3q3n5V1-WJV7CgJZGW3zXqfP2MR5zHVP6GNP377WSjW88mlCp7pTnw_W5h7WW74YYSGkW657LP11Kb4N3W4QdCTX79YrgzW611WXV3f649vW4P6Ftc4Bb8SQW8Dng1N3-7FsKW8mcL1T4Q6DZjW8JDt-H1x6dp1W4qKBcr1SLSGcW3b9SDH8VfgBLW6NbbXx34C8M1W4hGrJD3S_1ZVW2nQLWr7TWHPWW5jkfpG5PQ12dW8KLrjW3BhnNtW2kMcHq82THXFW69zMmh8jJZYD2kJ1): It uses data augmentation. Two different, random augmentations are applied to each example, and the model processes them separately to generate two different, but related, representations. The invariance term computes the distance between them. The greater the distance, the greater the penalty.

**Results:** The authors transferred the VICReg-trained ResNet-50’s representations to a linear classifier and trained it on ImageNet with labels. That model achieved a 73.2 percent accuracy, just shy of the 76.5 percent achieved by a supervised ResNet-50. A linear classifier using representations from a ResNet-50 pretrained using the contrastive learning method [SimCLR](https://info.deeplearning.ai/e3t/Btc/LX+113/cJhC404/VVHKnN1kyNsjW8FHScq6nY05mW8hW1h34wH5nzMXl4nJ3q3n5V1-WJV7CgG-gVfjcMt1XKKnlN90sc23JqkyjW5_dQCz8t_0DqW6WhLt36qKp5QW5HxRG168p80VW7DwLd15Wq8KnW8ywNWl8m1Rv4W5CDYs67pryk3W2CMsCr1w26SqN69yp4yKVqYXW5qDJfg2yR6v8W2Yl2cr5yRdLqW7gYtSC8nMP13W7Wm-Vx6p9xQMW1_hRzz2jQF3BW3Tctvy1d-G2BW7YCWpS6LDwbzN8-Bj3kNCx0FW6jVpt57wRQv4W1HL9bG5gpLfK3np71) achieved 69.3 percent accuracy.   
**Why it matters:** Contrastive learning, a successful pretraining technique, requires a large number of comparisons between dissimilar inputs to ensure that not all representations are identical. VICReg avoids that issue by computing the variance within a batch, a much less memory-intensive operation.  
**We’re thinking:** Comparing different augmentations of the same example has proven to be a powerful way to learn. This technique extends that approach, and we expect to see more.
 \> From \<[https://mail.google.com/mail/u/0/#inbox/FMfcgzGkbDSWrLpvXgDQfXpKpRpwxPFB](https://mail.google.com/mail/u/0/#inbox/FMfcgzGkbDSWrLpvXgDQfXpKpRpwxPFB)\>  

**Now That Machines Can Learn, Can They Unlearn?** 
 \> From \<[https://www.wired.com/story/machines-can-learn-can-they-unlearn/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=154938501&_hsenc=p2ANqtz-8GLVXfEMV7CJV8S4aWwIo6S-_RwoTY40V3QejUy_xuSuu-0UWVtNl-0Voc5G3jViDrLChZ6PQycjUHp2Y01Qf-mM7TBw&utm_content=154938501&utm_source=hs_email](https://www.wired.com/story/machines-can-learn-can-they-unlearn/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=154938501&_hsenc=p2ANqtz-8GLVXfEMV7CJV8S4aWwIo6S-_RwoTY40V3QejUy_xuSuu-0UWVtNl-0Voc5G3jViDrLChZ6PQycjUHp2Y01Qf-mM7TBw&utm_content=154938501&utm_source=hs_email)\>  

[https://ci5.googleusercontent.com/proxy/f-rIUYWQcvrkYlbEjO94x3YXDeq7MNsV4iO6cYP9ZKpfFR5K4NVnvuFzNv8gVecMdqQckNHCzNIlOLqid3G0lvOYt3d_ckgKu42dcqkZcNunA9_YtAA2sqJeWFLpqFODp0VUsCDkdC3FW4qAv3gj-Q=s0-d-e1-ft#https://info.deeplearning.ai/hs-fs/hubfs/unlearn.gif?width=1200&upscale=true&name=unlearn.gif](https://ci5.googleusercontent.com/proxy/f-rIUYWQcvrkYlbEjO94x3YXDeq7MNsV4iO6cYP9ZKpfFR5K4NVnvuFzNv8gVecMdqQckNHCzNIlOLqid3G0lvOYt3d_ckgKu42dcqkZcNunA9_YtAA2sqJeWFLpqFODp0VUsCDkdC3FW4qAv3gj-Q=s0-d-e1-ft#https://info.deeplearning.ai/hs-fs/hubfs/unlearn.gif?width=1200&upscale=true&name=unlearn.gif)
 
**Deep Unlearning**  
==Privacy advocates want deep learning systems to forget what they’ve learned.==   
**What’s new:** ==Researchers are seeking ways to remove the influence of particular training examples, such as an individual’s personal information, from a trained model without affecting its performance,== _Wired_ ==reported.==   
**How it works:** ==Some researchers have experimented with preparing data prior to training for potential removal later, while others have worked to remove the effect of selected examples retroactively.== 

- ==Researchers from the Universities of Toronto and Wisconsin-Madison== ==developed== ==a training method called SISA in which different versions of a model are trained on non-overlapping subsets of the same dataset. During inference, they combine the predictions from each model via majority vote. This makes it possible to remove selected training examples and retrain only the model associated with their subset.== 
- ==A team at Harvard, Stanford, and University of Pennsylvania later== ==showed== ==that SISA would fail to remove the influence of data if the requests to do so weren’t randomly distributed. The team mitigated this problem by introducing noise in the training algorithm based on ideas from== ==differential privacy====.==
- ==Researchers from Google, Cornell, and University of Waterloo== ==showed== ==how to remove the impact of a training example on a model’s weights if its loss function meets certain mathematical conditions.==

**Behind the news:** ==Evolving data privacy laws could wreak havoc on machine learning models.== 

- ==The European Union’s General Data Privacy Regulation includes a “right to be forgotten” that could force companies retroactively to remove the influence of specific data from trained models, some observers== ==argue====.==
- ==California’s== ==Privacy Rights Act gives citizens the right to know how their data is being used and request that it be deleted, even if it has been sold to a third party.== 

**Why it matters:** ==Enabling models to unlearn selectively and incrementally would be less costly than retraining repeatedly from scratch. It also could give users more control over how their data is used and who profits from it.==   
**We’re thinking:** ==Wait … what was this article about?==
 \> From \<[https://mail.google.com/mail/u/0/?tab=rm&ogbl&zx=y0t2j3lrw59a#inbox/FMfcgzGkbDccmLQwPfKZhhhQqCtMWcpg](https://mail.google.com/mail/u/0/?tab=rm&ogbl&zx=y0t2j3lrw59a#inbox/FMfcgzGkbDccmLQwPfKZhhhQqCtMWcpg)\>  

[https://arxiv.org/abs/2107.07567?utm_campaign=The%20Batch&utm_medium=email&_hsmi=187004716&_hsenc=p2ANqtz-8rLc5Vx8VgbOnYssNJ9XYnjhh3g8o27nIe8XD5GzKBw31ADXlP83N6ECcClPvDuF2VbrI_I4q7fKUgczWkyZGlIDbFTw&utm_content=187004196&utm_source=hs_email](https://arxiv.org/abs/2107.07567?utm_campaign=The%20Batch&utm_medium=email&_hsmi=187004716&_hsenc=p2ANqtz-8rLc5Vx8VgbOnYssNJ9XYnjhh3g8o27nIe8XD5GzKBw31ADXlP83N6ECcClPvDuF2VbrI_I4q7fKUgczWkyZGlIDbFTw&utm_content=187004196&utm_source=hs_email)

**Long-Haul Chatbot**  
==State-of-the-art chatbots typically are trained on short dialogs. Consequently they often respond with off-point statements in extended conversations. To improve that performance, researchers developed a way to track context throughout a conversation.==  
**What's new:** ==Jing Xu, Arthur Szlam, and Jason Weston at Facebook released a== ==chatbot== ==that summarizes dialog on the fly and uses the summary to generate further repartee.==  
**Key insight:** ==Chatbots based on the transformer architecture typically generate replies by analyzing up to 1,024 of the most recent tokens (usually characters, words, or portions of words). Facebook== ==previously== ==used a separate transformer to determine which earlier statements were most relevant to a particular reply== ==—== ==but in long conversations, the relevant statements may encompass more than 1,024 tokens. Summarizing such information can give a model access to more context than is available to even large, open-domain chatbots like== ==BlenderBot====,== ==Meena====, and== ==BART====.==  
**How it works:** ==The authors built a== ==dataset== ==of over 5,000 conversations. They trained a system of three transformers respectively to summarize conversations as they occurred, select the five summaries most relevant to the latest back-and-forth turn, and generate a response.==

- ==The authors recorded text chats between pairs of volunteers. Each conversation consisted of three or four sessions (up to 14 messages each) separated by pauses that lasted up to seven days.==
- ==After each session, a volunteer summarized the session to serve as reference for subsequent sessions (which may involve different conversants). In addition, the volunteer either summarized each turn or marked it with a label indicating that no summary was needed.==
- ==A== ==BlenderBot====, given a dialog from the start through each turn, learned to match the turn-by-turn summaries.==
- ==A== ==dense passage retriever====, pretrained on question-answer pairs,== ==ranked and selected== ==the turn-by-turn summaries most relevant to the session so far according to nearest neighbor search.== 
- ==A separate BlenderBot received the top summaries and generated the next response.==

**Results:** ==Human evaluators compared the authors====’== ==model to a garden-variety BlenderBot, which draws context from the most recent 128 tokens. They scored the authors====’== ==model an average 3.65 out of 5 compared with the BlenderBot====’====s 3.47. They found 62.1 percent of its responses engaging versus 56.5 percent of the BlenderBot====’====s responses.==  
**Why it matters:** ==After much work on enabling chatbots to discuss a variety of topics, it====’====s good to see improvement in their ability to converse at length. Conversation is inherently dynamic, and if we want chatbots to keep up with us, we need them to ride a train of thought, hop off the line, switch to a new rail, and shift back to the first== ==—== ==all without losing track.==  
**We're thinking:** ==If Facebook were to use this system to generate chatter on the social network, could we call its output Meta data? (Hat tip to Carol-Jean Wu!).==
 \> From \<[https://mail.google.com/mail/u/0/?tab=rm&ogbl#inbox/FMfcgzGllCfhcDHsfvZXVfNJJFvstvbh](https://mail.google.com/mail/u/0/?tab=rm&ogbl#inbox/FMfcgzGllCfhcDHsfvZXVfNJJFvstvbh)\>
==Stopped at Keycloak/Windows authentication==

1. Κριτήριο για το setup σου (RTX 3060 Laptop, 6GB VRAM)

* “Άνετα” σε GPU: 2B–7B μοντέλα, κατά προτίμηση με πιο «ελαφριά» quantization (συνήθως Q4 στα περισσότερα pulls της Ollama).
* “Οριακά”: 8B (μπορεί να κάνει partial offload/πτώση ταχύτητας, ειδικά με μεγάλο context).
* “Μην ασχολείσαι”: 9B+ (σχεδόν πάντα θα σε πάει σε RAM/CPU ή θα είναι ασφυκτικό), και οτιδήποτε 13B+.

2. Φιλτραρισμένη λίστα μοντέλων για να δοκιμάσεις (συνιστώμενα)

* `llama3.2:3b`
* `phi3:mini`
* `gemma2:2b`
* `mistral:7b`
* `qwen2.5:7b` (καλή επιλογή αν το έχεις διαθέσιμο στην Ollama)
* `codellama:7b` (αν σε νοιάζει κυρίως code)

3. Οριακά για 6GB (μόνο αν αποδέχεσαι ότι ίσως δεν είναι full-GPU)

* `llama3.1:8b` ή `llama3:8b` (ανάλογα τι έχεις διαθέσιμο)

  * Αν το τρέξεις, κράτα context χαμηλά (π.χ. 2k–4k) για να μη σε πνίξει το KV cache.

4. Απόφυγε με 6GB

* `gemma2:9b` (συχνά borderline/εκτός)
* `phi3:medium` (14B)
* οτιδήποτε `13b`, `14b`, `27b`, `33b`, `70b`
* multimodal τύπου `llava` (συνήθως θέλουν παραπάνω VRAM για να δουλεύουν άνετα)

5. Πρακτικός έλεγχος ότι όντως πατάει GPU

* Σε άλλο terminal:

```bash
watch -n 1 nvidia-smi
```

* Τρέχεις model, και αν δεις σταθερή VRAM δέσμευση + GPU util να ανεβαίνει, είσαι ΟΚ. Αν VRAM μένει χαμηλά και CPU βαράει, έχεις fallback.

Συμπέρασμα

* Μείνε σε `3b–7b` (llama3.2:3b, phi3:mini, gemma2:2b, mistral:7b, qwen2.5:7b).
* 8B μόνο δοκιμαστικά και με μικρό context. 9B+ άστο.


![[Attachments/Current/2026-02-11.md/image.png|350]]![[Attachments/Current/2026-02-11.md/image-1.png|350]]

![[Attachments/Current/2026-02-11.md/image-4.png|350]]![[Attachments/Current/2026-02-11.md/image-2.png|350]]

##### Start ollama container
`docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

##### Run model locally
Now you can run a model:

`docker exec -it ollama ollama run llama3`


> [!NOTE] Copied from:
> Docker Hub ollama image info

\>Copied from: Docker Hub ollama image info

![[Drawing 2026-02-10 10.15.10.excalidraw]]
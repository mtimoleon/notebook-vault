Clipped from: [https://www.webzein.gr/blog/19/pos-na-ftiaxete-ena-chatbot-gia-ta-eggrafa-sas-me-montelo-gpt](https://www.webzein.gr/blog/19/pos-na-ftiaxete-ena-chatbot-gia-ta-eggrafa-sas-me-montelo-gpt)
 
Η συνομιλία με το ChatGPT είναι διασκεδαστική αφού μπορεί κανείς να εξερευνήσει διάφορες ιδέες για μάθηση ή απλά ενημέρωση. Όλη αυτή η καινοτομία όμως μπορεί να πάει στράφι, ειδικά αν σκεφτεί κανείς ότι τα μοντέλα μάθησης υποφέρουν ακόμα από παιδικές ασθένειες (βλ "ψευδαισθήσεις" κλπ) όπως κάθε νέα τεχνολογία. Πώς θα μπορούσαμε να το χρησιμοποιήσουμε με πιο παραγωγικό τρόπο;  
Η απάντηση είναι ότι με το GPT API της OpenAI, μπορούμε να κάνουμε πολύ περισσότερα από το να συνομιλούμε για πλάκα με ένα chatbot. Μια πολύ πιο παραγωγική χρήση, για επιχειρήσεις αλλά και για προσωπική χρήση, είναι το Q&A (Ερώτηση-Απάντηση), δηλαδή να ρωτάτε το chatbot σε φυσική γλώσσα για τα δικά σας έγγραφα / δεδομένα και αυτό να σας απαντά γρήγορα ανακτώντας πληροφορίες από τα έγγραφα και δημιουργώντας μια "φυσική" απάντηση. Μπορείτε να αξιοποιήσετε αυτήν την ιδέα για υποστήριξη πελατών, έρευνα χρηστών, διαχείριση γνώσης και πολλά άλλα!  
Σε αυτό το άρθρο, θα δείτε βήμα προς βήμα πώς μπορείτε να δημιουργήσετε το δικό σας Q&A chatbot με τα έγγραφά σας, με το LlamaIndex και το GPT API. Αρχικά θα δούμε το γιατί ορισμένες προσεγγίσεις δε θα λειτουργήσουν. Εάν σας ενδιαφέρει απλώς να δείτε πώς να δημιουργήσετε το Q&A chatbot, μπορείτε να πάτε απευθείας στη μεθεπόμενη ενότητα «Βήμα προς βήμα: Δημιουργία Q&A chatbot για έγγραφα».

### **Εξερευνώντας διαφορετικές προσεγγίσεις**

Μια πρώτη ιδέα θα ήταν η "τελειοποίηση" του μοντέλου GPT με τα δικά μας data, μια διαδικασία που κοστίζει αρκετά χρήματα και απαιτεί ένα μεγάλο σύνολο δεδομένων με παραδείγματα. Είναι επίσης αδύνατο να ρυθμιστεί με ακρίβεια κάθε φορά που υπάρχει μια αλλαγή σε ένα έγγραφο. Ένα ακόμη πιο προβληματικό σημείο είναι ότι η τελειοποίηση του μοντέλου απλά ΔΕΝ ΜΠΟΡΕΙ να κάνει το μοντέλο να "μάθει" όλες τις πληροφορίες στα έγγραφα, αλλά μάλλον πρέπει να διδάσκει στο μοντέλο αυτή τη νέα δεξιότητα. Επομένως, για ένα QA με πολλά έγγραφα, η τελειοποίηση δεν είναι ο σωστός τρόπος.  
Μια άλλη προσέγγιση θα ήταν να δίνουμε ένα "πλαίσιο" στις ερωτήσεις μας. Για παράδειγμα, αντί να κάνουμε μια ερώτηση απευθείας, θα μπορούσαμε να προσθέσουμε το έγγραφο που μας ενδιαφέρει πριν θέσουμε στο bot την πραγματική ερώτηση. Αλλά το μοντέλο GPT έχει περιορισμένη διάρκεια προσοχής. Μπορεί να δεχτεί μόνο μερικές χιλιάδες λέξεις σε κάθε prompt (~3000 λέξεις). Είναι αδύνατο λοιπόν να του δώσουμε όλο το "πλαίσιο" σε μια ερώτηση, χώρια ότι θα έπρεπε να το κάνουμε αυτό για χιλιάδες έγγραφα που θα έπρεπε να έχουμε ήδη στη διάθεσή μας, π.χ. μηνύματα ηλεκτρονικού ταχυδρομείου με σχόλια πελατών ή/και εκατοντάδες έγγραφα προϊόντων. Είναι επίσης δαπανηρό επειδή η τιμολόγηση του API βασίζεται στον αριθμό των tokens που χρησιμοποιείτε.  
Λόγω των παραπάνω περιορισμών, μια καλύτερη ιδέα είναι να χρησιμοποιήσουμε πρώτα έναν αλγόριθμο για να αναζητήσουμε τα έγγραφα, να διαλέξουμε τα σχετικά αποσπάσματα και στη συνέχεια να "περάσουμε" μόνο αυτά στο μοντέλο GPT ως context με τις ερωτήσεις μας. Για τον σκοπό αυτό μας χρειάζεται η προγραμματιστική βιβλιοθήκη LlamaIndex ([https://github.com/jerryjliu/llama_index](https://github.com/jerryjliu/llama_index)), η οποία είναι απλή στη χρήση.  
Στην επόμενη ενότητα, θα δούμε βήμα προς βήμα τη χρήση του LlamaIndex και του GPT για τη δημιουργία ενός Q&A chatbot στα δικά μας δεδομένα.

### **Βήμα προς βήμα: Δημιουργία Q&A chatbot για έγγραφα**

Θα δημιουργήσουμε ένα Q&A chatbot βασισμένο στα έγγραφα μας με το LlamaIndex και το GPT (text-davinci-003), ώστε να κάνουμε ερωτήσεις και να λαμβάνουμε μια απάντηση από το chatbot, όλα σε φυσική γλώσσα.  
**Προϋποθέσεις**  
Πριν ξεκινήσουμε, πρέπει να έχουμε μερικά πράγματα:

- Το κλειδί API OpenAI, το οποίο μπορείτε να βρείτε στη διεύθυνση [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
- Μια βάση δεδομένων των εγγράφων. Το LlamaIndex υποστηρίζει πολλές διαφορετικές πηγές δεδομένων (Google Docs, Notion, Asana, κλπ). Εδώ, θα χρησιμοποιήσουμε ένα απλό αρχείο κειμένου για επίδειξη.
- Ένα περιβάλλον Python ή ένα [online Google Colab notebook](https://colab.research.google.com/).

**Πως θα δουλεύει**  
Η ροή εργασίας είναι απλή και αποτελείται από μερικά μόνο βήματα:  
    1. Δημιουργία ενός ευρετηρίου των εγγράφων με το LlamaIndex  
    2. Ερώτημα στο ευρετήριο με φυσική γλώσσα  
    3. Το LlamaIndex ανακτά τα σχετικά μέρη και τα μεταβιβάζει στο GPT  
    4. Ερώτημα στο GPT με το σχετικό πλαίσιο και δημιουργία μια απάντησης  
Αυτό που κάνει το LlamaIndex ουσιαστικά είναι να μετατρέψει τα αρχικά δεδομένα των εγγράφων σας σε ένα διανυσματικό ευρετήριο, το οποίο είναι πολύ αποτελεσματικό για την υποβολή ερωτημάτων. Θα χρησιμοποιήσει αυτό το ευρετήριο για να βρει τα πιο σχετικά μέρη με βάση την ομοιότητα του ερωτήματος και των δεδομένων. Στη συνέχεια, θα συνδέσει τα αποτελέσματα στο prompt που θα στείλει στο GPT, έτσι ώστε το GPT να έχει το "πλαίσιο" για να απαντήσει στην ερώτησή σας.  
**Ρυθμίσεις**  
Πρώτα θα εγκαταστήσουμε τις βιβλιοθήκες. Δώστε τις παρακάτω εντολές στο τερματικό σας ή στο σημειωματάριο Google Colab. Αυτές οι εντολές θα εγκαταστήσουν τόσο το LlamaIndex όσο και το OpenAI.  
pip install llama-index￼pip install openai  
Στη συνέχεια, σε ένα νέο αρχείο .py, θα εισαγάγουμε τις βιβλιοθήκες στην python και θα ρυθμίσουμε το κλειδί API OpenAI. Να τι πρέπει να γράψουμε στο αρχείο:  
from llama_index import GPTSimpleVectorIndex, Document, SimpleDirectoryReader￼import os￼os.environ['OPENAI_API_KEY'] = 'YOUR-GPI-API-KEY' # αντικαταστήστε το με το κλειδί σας.

### **Κατασκευή του ευρετηρίου**

Στη συνέχεια, θα δημιουργήσουμε ένα ευρετήριο του εγγράφου μας. Για να φορτώσετε τα έγγραφά σας, μπορείτε να χρησιμοποιήσετε τη μέθοδο SimpleDirectoryReader που παρέχεται από το LllamaIndex (ή μπορείτε να το φορτώσετε από strings), κάπως έτσι.  
# Φόρτωση από κατάλογο στο δίσκο￼documents = SimpleDirectoryReader('your_directory').load_data()￼# Φόρτωση από strings: text1, text2, ...￼text_list = [text1, text2, ...]￼documents = [Document(t) for t in text_list]  
Το LlamaIndex έχει επίσης μια ποικιλία συνδέσμων δεδομένων (Notion, Asana, Google Drive, Obsidian, κλπ). Μπορείτε να τις βρείτε στη διεύθυνση [https://llamahub.ai/](https://llamahub.ai/).  
Μετά τη φόρτωση των εγγράφων, μπορούμε στη συνέχεια να κατασκευάσουμε το ευρετήριο απλά με  
index = GPTSimpleVectorIndex(documents)  
Εάν θέλετε να αποθηκεύσετε το ευρετήριο και να το φορτώσετε για μελλοντική χρήση, μπορείτε να χρησιμοποιήσετε τις ακόλουθες μεθόδους  
# Αποθήκευση ευρετηρίου σε ένα index.json αρχείο￼index.save_to_disk('index.json')￼# Και αργότερα, φόρτωση του ευρετηρίου από το αρχείο index.json￼index = GPTSimpleVectorIndex.load_from_disk('index.json')  
**Υποβολή ερωτημάτων στο ευρετήριο και λήψη απάντησης**  
Η υποβολή ερωτημάτων στο ευρετήριο είναι απλή:  
response = index.query("What features do users want to see in the app?")￼print(response)  
Και θα λάβετε την απάντησή σας τυπωμένη. Το LlamaIndex θα πάρει την ερώτησή σας, θα αναζητήσει σχετικά κομμάτια στο ευρετήριο και θα στείλει στο GPT το ερώτημα σας μαζί με τα σχετικά κομμάτια που βρήκε...  
**Μερικές extras για προηγμένη χρήση**  
Τα παραπάνω βήματα είναι απλά μια πολύ απλή εκκίνηση για να στήσετε ένα Q&A bot με το LlamaIndex και το GPT. Αλλά μπορείτε να κάνετε πολύ περισσότερα. Στην πραγματικότητα, μπορείτε να ρυθμίσετε το LlamaIndex ώστε να χρησιμοποιεί ένα διαφορετικό μοντέλο LLM, να χρησιμοποιεί διαφορετικό τύπο ευρετηρίου για διαφορετικές εργασίες, να ενημερώνει τους υπάρχοντες δείκτες με ένα νέο ευρετήριο κ.λπ. Αν σας ενδιαφέρει, μπορείτε να διαβάσετε περισσότερα στη διεύθυνση [https://gpt-index.readthedocs.io/en/latest/index.html](https://gpt-index.readthedocs.io/en/latest/index.html)